{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import Counter\n",
    "from isbnlib import meta\n",
    "from isbnlib.registry import bibformatters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:33:51.045725Z",
     "end_time": "2023-05-07T17:33:51.072829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#nainÅ¡talujte\n",
    "#!pip install isbnlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:33:51.750700Z",
     "end_time": "2023-05-07T17:33:51.766835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "ISBN\n0439023483    21398\n030758836X    19867\n0439023513    14114\n0385537859    12973\n0007444117    12629\n              ...  \n0821510401        1\n0821508717        1\n1939084261        1\n1939084768        1\n1453758569        1\nName: count, Length: 2330066, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "ID_reviewer\nA14OJS0VWMOSWO    43201\nAFVQZQ8PW0L       28816\nA2F6N60Z96CAJI     6121\nA320TMDV6KCFU      5955\nA2OJW07GQRNJUT     5443\n                  ...  \nA38P6AZHJE19JU        1\nA2UOFPPO08D0W9        1\nA1IMFOGM4ZOAY2        1\nA3MD9VU1YCUS4Y        1\nA8W4BR3HGGS3C         1\nName: count, Length: 8026324, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df = pd.read_csv('data/rec-amz-Books.edges', header=None, names=['ID_reviewer', 'ISBN', 'Stars', 'Date'])\n",
    "# display(df['ISBN'].value_counts())\n",
    "# display(df['ID_reviewer'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:33:51.913349Z",
     "end_time": "2023-05-07T17:34:23.557094Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 56.5 GiB for an array with shape (87085, 87085) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[59], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m87085\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m87085\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\numeric.py:205\u001B[0m, in \u001B[0;36mones\u001B[1;34m(shape, dtype, order, like)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ones_with_like(shape, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, like\u001B[38;5;241m=\u001B[39mlike)\n\u001B[1;32m--> 205\u001B[0m a \u001B[38;5;241m=\u001B[39m empty(shape, dtype, order)\n\u001B[0;32m    206\u001B[0m multiarray\u001B[38;5;241m.\u001B[39mcopyto(a, \u001B[38;5;241m1\u001B[39m, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 56.5 GiB for an array with shape (87085, 87085) and data type float64"
     ]
    }
   ],
   "source": [
    "# np.ones((87085, 87085))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 780. TiB for an array with shape (10356390, 10356390) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10356390\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10356390\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\numeric.py:205\u001B[0m, in \u001B[0;36mones\u001B[1;34m(shape, dtype, order, like)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ones_with_like(shape, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, like\u001B[38;5;241m=\u001B[39mlike)\n\u001B[1;32m--> 205\u001B[0m a \u001B[38;5;241m=\u001B[39m empty(shape, dtype, order)\n\u001B[0;32m    206\u001B[0m multiarray\u001B[38;5;241m.\u001B[39mcopyto(a, \u001B[38;5;241m1\u001B[39m, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 780. TiB for an array with shape (10356390, 10356390) and data type float64"
     ]
    }
   ],
   "source": [
    "# np.ones((10356390, 10356390))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def subgraphByListOfValues(values: pd.Series, column: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[np.isin(df[column], values)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:04:33.537998Z",
     "end_time": "2023-05-07T17:04:33.620006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def randomSubgraph(n:int, column: str, df: pd.DataFrame, weighed: bool = True, seed: int = 3, minDeg: int= 10) -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    values, counts = np.unique(df[column], return_counts=True)\n",
    "    values, counts = values[counts > minDeg],  counts[counts > minDeg] # nech nemame knihy s velmi malo hodnoteniami (resp uzivatelov co majo citaju)\n",
    "    return subgraphByListOfValues(np.random.choice(values, n, replace=False, p=(counts / sum(counts)) if weighed else None), column, df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:04:33.546112Z",
     "end_time": "2023-05-07T17:04:33.620006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class RecommendationEngine:\n",
    "    def __init__(self, filename: str, seed: int=3, n: int = 200, col: str = \"ISBN\"):\n",
    "        self.df = pd.read_csv(filename, header=None, names=['ID_reviewer', 'ISBN','Stars','Date'])\n",
    "        self.subdf = randomSubgraph(n, col, self.df, seed=seed)\n",
    "        self.SM = {True: None, False: None}\n",
    "        self.SMC = {True: None, False: None}\n",
    "        self.G: nx.classes.graph.Graph = nx.from_pandas_edgelist(self.subdf, source='ID_reviewer', target='ISBN', edge_attr='Stars')\n",
    "        self.userOrder = self.filterNodes(True)\n",
    "        self.bookOrder = self.filterNodes(False)\n",
    "\n",
    "    def filterNodes(self, users: bool) -> list[str]:\n",
    "        return list(filter(lambda x: (x[0] == 'A') if users else (x[0] != 'A'), self.G.nodes()))\n",
    "\n",
    "    def similarityMatrix(self, users: bool, save: bool=False) -> pd.DataFrame:  # use wisely!\n",
    "        if self.SM[users] is not None:\n",
    "            return self.SM[users]\n",
    "        userOrder = self.filterNodes(True)\n",
    "        bookOrder = self.filterNodes(False)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder, bookOrder).toarray()\n",
    "        product = A @ A.T if users else A.T @ A\n",
    "        np.fill_diagonal(product, 0)\n",
    "        order = userOrder if users else bookOrder\n",
    "        SM = pd.DataFrame(product, columns = order)\n",
    "        SM.index = order\n",
    "        if save:\n",
    "            self.SM[users] = SM\n",
    "        return SM\n",
    "\n",
    "    def similarityMatrixCosine(self, users: bool, save: bool=False) -> np.ndarray:  # use wisely!\n",
    "        # filterList = self.filterNodes(users)\n",
    "        if self.SMC[users] is not None:\n",
    "            return self.SMC[users]\n",
    "        SM = self.similarityMatrix(users)\n",
    "        norms = (np.linalg.norm(SM, axis=1))\n",
    "        SMC = SM / norms[:, None] / norms[None, :]\n",
    "        np.nan_to_num(SMC, copy=False)\n",
    "        if save:\n",
    "            self.SMC[users] = SMC\n",
    "        return SMC\n",
    "\n",
    "    def similarityVectorForUser(self, user:str, userOrder:list[str] = None, cosine:bool = True):\n",
    "        if userOrder is None:\n",
    "            userOrder = self.filterNodes(True)\n",
    "        u = userOrder.index(user)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder).toarray()\n",
    "        result = np.zeros((len(userOrder)))\n",
    "        for r in range(len(userOrder)):\n",
    "            result[r] = np.dot(A[r, :], A[u, :])\n",
    "            if cosine:\n",
    "                result[r] /= np.sqrt(np.dot(A[r, :], A[r, :]))\n",
    "        if cosine:\n",
    "            result /= np.sqrt(np.dot(A[u, :], A[u, :]))\n",
    "        result[u] = 0\n",
    "        return result, np.array(userOrder)\n",
    "\n",
    "    def getNMostSimilarUsers(self, user:str, n:int, ignoreTotalMatch=True):\n",
    "        sim, users = self.similarityVectorForUser(user, cosine=True)\n",
    "        if ignoreTotalMatch:\n",
    "            sim, users = sim[sim < 0.9999], users[sim < 0.9999]\n",
    "        sim.argsort()\n",
    "        return users[sim.argsort()[-n:]]\n",
    "\n",
    "    def getSimilarBooksToABook(self, book):\n",
    "        df = self.similarityMatrixCosine(False)\n",
    "        return list(df[book][df[book] == df[book].max()].index)\n",
    "\n",
    "    def getMetaFromISBN(self,isbn:str) -> json:\n",
    "      SERVICE = \"goob\"\n",
    "      format_json = bibformatters[\"json\"]\n",
    "      meta_data = (format_json(meta(isbn, SERVICE)))\n",
    "      #print(meta_data)\n",
    "      return meta_data\n",
    "\n",
    "    def fromJsonToDict(self,json_file:json) -> dict:\n",
    "      return json.loads(json_file)\n",
    "\n",
    "    def getDf(self)->pd.DataFrame:\n",
    "      return self.subdf\n",
    "\n",
    "    def getBooksByUser(self,df:pd.DataFrame,id:str) ->list: #(list of ISBN for user)\n",
    "      df = df.loc[df['ID_reviewer']==id, 'ISBN'].values\n",
    "      return df\n",
    "\n",
    "    def getBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list: #same - same books, diff - different books\n",
    "      b1 = self.getBooksByUser(self.getDf(),id1)\n",
    "      b2 = self.getBooksByUser(self.getDf(),id2)\n",
    "      if type_ == \"same\":\n",
    "        return list(set(b1).intersection(set(b2)))\n",
    "      elif type_ == \"diff1\":\n",
    "        return list(set(b2) - set(b1)) #vsetky knihy od id2, ktore id1 necital\n",
    "      elif type_ == \"diff2\":\n",
    "        return list(set(b1) - set(b2)) #vsetky knihy od id1, ktore id2 necital\n",
    "\n",
    "    def getSimilarBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list:  #type ==(year, publisher)\n",
    "        if type_ == \"year\": #odporucame id1 knihy od uzivatela id2 na zaklade roku vydania knihy\n",
    "          books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "          #print(books_s)\n",
    "          years = list()\n",
    "          for i in range(len(books_s)): #zoberieme vseetky roky a pozrieme sa aky najviac prevlada -> zoberiem okolie (-5,5) a to odporucime\n",
    "            pom = self.getMetaFromISBN(books_s[i])\n",
    "            if pom != None: #nenaslo ISBN\n",
    "              years.append(self.fromJsonToDict(pom)[\"year\"])\n",
    "          most_common_era = Counter(years).most_common(1) #rok,pocet_opakovani\n",
    "          most_common_era = [int(most_common_era[0][0])-5,int(most_common_era[0][0])+5]\n",
    "          #print(most_common_era)\n",
    "          books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "          recommendation_by_year = list()\n",
    "          for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su medzi most_common_era\n",
    "            pom = self.getMetaFromISBN(books_d[i])\n",
    "            if pom != None: #nenaslo ISBN\n",
    "              if most_common_era[0] <= (int(self.fromJsonToDict(pom)[\"year\"])) <= most_common_era[1]:\n",
    "                title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                authors = list()\n",
    "                for i in range(len(self.fromJsonToDict(pom)[\"author\"])):  #ak mame viac autorov\n",
    "                  authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                recommendation_by_year.append([title,year, authors])\n",
    "                #print(recommendation_by_year)\n",
    "          if recommendation_by_year == []:\n",
    "            recommendation_by_year = [(\"Nenasli sa ziadne knihy z rokov:\",most_common_era[0],\"-\",most_common_era[1])]\n",
    "          return recommendation_by_year\n",
    "\n",
    "        elif type_ == \"publisher\": #odporucame id1 knihy od uzivatela id2, vyberame oblubeneho vydavatelstvo\n",
    "           books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "           publishers = list()\n",
    "           for i in range(len(books_s)): #zoberieme vseetky vydavatelstva -> most_common\n",
    "              pom = self.getMetaFromISBN(books_s[i])\n",
    "              if pom != None: #nenaslo ISBN\n",
    "                publishers.append(self.fromJsonToDict(pom)[\"publisher\"])\n",
    "           most_common_publisher = Counter(publishers).most_common(1) #vydavatelstvo,pocet_opakovani\n",
    "           print(most_common_publisher)\n",
    "           books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "           recommendation_by_publisher = list()\n",
    "           for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su od most_common_publishe\n",
    "              pom = self.getMetaFromISBN(books_d[i])\n",
    "              if pom != None: #nenaslo ISBN\n",
    "                if most_common_publisher[0] == (self.fromJsonToDict(pom)[\"publisher\"]):\n",
    "                  title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                  year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                  authors = list()\n",
    "                  for i in range(len(self.fromJsonToDict(pom)[\"author\"])): #ak mame viac autorov\n",
    "                    authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                  recommendation_by_publisher.append([title,year, authors])\n",
    "                #print(recommendation_by_year)\n",
    "           if recommendation_by_publisher == []:\n",
    "              recommendation_by_publisher = [\"Nenasli sa ziadne knihy od oblubeneho vydavatela\"]\n",
    "           return recommendation_by_publisher\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:04:33.651266Z",
     "end_time": "2023-05-07T17:04:33.713537Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:04:33.698828Z",
     "end_time": "2023-05-07T17:06:00.173863Z"
    }
   },
   "outputs": [],
   "source": [
    "re = RecommendationEngine('data/rec-amz-Books.edges', n=200, seed=76972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 87085\n"
     ]
    }
   ],
   "source": [
    "print(f'number of users: {len(re.filterNodes(True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:11:31.093030Z",
     "end_time": "2023-05-07T17:11:31.097543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar books to 0061537934: ['1937387704']\n",
      "3 most similar users to A3FI8DSH1SSBVU: ['A3H4CJRX3E9H4W' 'A3JQ1OHUQI4M58' 'A39L6AGSD5ODRA']\n",
      "most similar books to 0974504874: ['0307476073']\n"
     ]
    }
   ],
   "source": [
    "randomUser = np.random.choice(re.filterNodes(True))\n",
    "randomBook = np.random.choice(re.filterNodes(False))\n",
    "print(f'3 most similar users to {randomUser}: {re.getNMostSimilarUsers(randomUser, 3)}')\n",
    "print(f'most similar books to {randomBook}: {re.getSimilarBooksToABook(randomBook)}')# vela podobnych znamena, ze kniha si nie je podobna so ziadnou knihou, teda je izolovana"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T17:20:28.285628Z",
     "end_time": "2023-05-07T17:21:21.183008Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ukazkovy outupt:\n",
    "most similar books to 1858600073: ['0786407735']\n",
    "ku knihe \"They Walked With Jesus: Past Life Experience With Christ\", to naslo \"Genocide and Rescue in Wolyn: Recollections of the Ukrainian Nationalist Ethnic Cleansing Campaign Against the Poles During World War II\", co myslim nie je uplne odveci odporucanie (na to aku malu podmnozinu knih mame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pri hladani podobnych uzivatelov ignoreTotalMatch paraemter True ignoruje dokonale podobnych pouzivatelov, ty bu nemali ake ine knihy odporucit\n",
    "pri podobnych knihach, uz chceme ja dokolane zhody"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "            0060735457  0060757353  0061148520  0061240443  0061451835   \n0060735457           0           0           0           0           0  \\\n0060757353           0           0           0           0           0   \n0061148520           0           0           0           0           0   \n0061240443           0           0           0           0           0   \n0061451835           0           0           0           0           0   \n...                ...         ...         ...         ...         ...   \nB00HRIIVI6           0           0           0           0           0   \nB00HUHUA2O           0           0           0           0           0   \nB00KXCR422           0           0           0           0           0   \nB00L9HIR4E           0           0           0           0           0   \nB00LAOB6PI           0           0           0           0           0   \n\n            0061950726  006204964X  0062094661  0062265423  0133109895  ...   \n0060735457           0           0           0           0           0  ...  \\\n0060757353           2           0           0           0           0  ...   \n0061148520           0           0           0           0           0  ...   \n0061240443           4           0           1           0           0  ...   \n0061451835           2           1           0           0           0  ...   \n...                ...         ...         ...         ...         ...  ...   \nB00HRIIVI6           0           0           0           0           0  ...   \nB00HUHUA2O           0           0           0           0           0  ...   \nB00KXCR422           0           0           0           0           0  ...   \nB00L9HIR4E           0           0           0           0           0  ...   \nB00LAOB6PI           0           0           0           0           0  ...   \n\n            B00CQAPWFK  B00DDUYNXE  B00ED1QGXC  B00H0MFT2A  B00HHYCIIE   \n0060735457           0           0           0           0           0  \\\n0060757353           0           0           0           0           0   \n0061148520           0           0           1           0           0   \n0061240443           0           0           0           0           0   \n0061451835           0           0           0           0           0   \n...                ...         ...         ...         ...         ...   \nB00HRIIVI6           0           0           0           0           0   \nB00HUHUA2O           0           0           0           0           0   \nB00KXCR422           0           0           0           0           0   \nB00L9HIR4E           0           0           0           0           0   \nB00LAOB6PI           0           0           0           0           0   \n\n            B00HRIIVI6  B00HUHUA2O  B00KXCR422  B00L9HIR4E  B00LAOB6PI  \n0060735457           0           0           0           0           0  \n0060757353           0           0           0           0           0  \n0061148520           0           0           0           0           0  \n0061240443           0           0           0           0           0  \n0061451835           0           0           0           0           0  \n...                ...         ...         ...         ...         ...  \nB00HRIIVI6           0           0           0           0           0  \nB00HUHUA2O           0           0           0           0           0  \nB00KXCR422           0           0           0           0           0  \nB00L9HIR4E           0           0           0           0           0  \nB00LAOB6PI           0           0           0           0           0  \n\n[200 rows x 200 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0060735457</th>\n      <th>0060757353</th>\n      <th>0061148520</th>\n      <th>0061240443</th>\n      <th>0061451835</th>\n      <th>0061950726</th>\n      <th>006204964X</th>\n      <th>0062094661</th>\n      <th>0062265423</th>\n      <th>0133109895</th>\n      <th>...</th>\n      <th>B00CQAPWFK</th>\n      <th>B00DDUYNXE</th>\n      <th>B00ED1QGXC</th>\n      <th>B00H0MFT2A</th>\n      <th>B00HHYCIIE</th>\n      <th>B00HRIIVI6</th>\n      <th>B00HUHUA2O</th>\n      <th>B00KXCR422</th>\n      <th>B00L9HIR4E</th>\n      <th>B00LAOB6PI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0060735457</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0060757353</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0061148520</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0061240443</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0061451835</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>B00HRIIVI6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00HUHUA2O</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00KXCR422</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00L9HIR4E</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00LAOB6PI</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã 200 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(re.similarityMatrix(False, save=True))\n",
    "# pre users je matica moc velka...n neodporucam to skusat, a ani pre vela knih, to dlho trava..., lebo je tem vela user-ov, ale za cca min to zvladne"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T16:13:17.052451Z",
     "end_time": "2023-05-07T16:14:10.544574Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pre cast niszie, novy seed asi dost upravil podmnozinu pouzivatelov a knih, ktora bola vybrana"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'book', 'title': 'Heavenly Highway Hymns: Shaped-Note Hymnal', 'author': [{'name': 'Stamps/Baxter'}], 'year': '1983', 'identifier': [{'type': 'ISBN', 'id': '9780000013712'}], 'publisher': 'Brentwood Benson'}\n",
      "Brentwood Benson\n"
     ]
    }
   ],
   "source": [
    "meta_json_book = re.getMetaFromISBN(\"0000013714\")\n",
    "list_meta = re.fromJsonToDict(meta_json_book)\n",
    "print(list_meta)\n",
    "print(list_meta[\"publisher\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T16:14:10.544574Z",
     "end_time": "2023-05-07T16:14:11.193608Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "same: []\n",
      "diff1: ['076792066X']\n",
      "diff2: []\n"
     ]
    }
   ],
   "source": [
    "print(re.getBooksByUser(re.getDf(),\"A1KP12IVP6LAGL\"))\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"same\")\n",
    "print(\"same:\" ,books_users)\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"diff1\")\n",
    "print(\"diff1:\" ,books_users)\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"diff2\")\n",
    "print(\"diff2:\" ,books_users)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-07T16:14:11.198934Z",
     "end_time": "2023-05-07T16:14:11.276282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation by year: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecommendation by year: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m books_recomendation \u001B[38;5;241m=\u001B[39m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetSimilarBooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetDf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mA1KP12IVP6LAGL\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAG7R3MMF8QLDT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(books_recomendation)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecommendation by publisher: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[52], line 135\u001B[0m, in \u001B[0;36mRecommendationEngine.getSimilarBooks\u001B[1;34m(self, df, id1, id2, type_)\u001B[0m\n\u001B[0;32m    133\u001B[0m     years\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfromJsonToDict(pom)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    134\u001B[0m most_common_era \u001B[38;5;241m=\u001B[39m Counter(years)\u001B[38;5;241m.\u001B[39mmost_common(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m#rok,pocet_opakovani\u001B[39;00m\n\u001B[1;32m--> 135\u001B[0m most_common_era \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(\u001B[43mmost_common_era\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5\u001B[39m,\u001B[38;5;28mint\u001B[39m(most_common_era[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m5\u001B[39m]\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m#print(most_common_era)\u001B[39;00m\n\u001B[0;32m    137\u001B[0m books_d \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgetBooks(df,id1,id2,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiff1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Recommendation by year: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"year\")\n",
    "print(books_recomendation)\n",
    "print(\"Recommendation by publisher: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"publisher\")\n",
    "print(books_recomendation)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
