{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import Counter\n",
    "from isbnlib import meta\n",
    "from isbnlib.registry import bibformatters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:19.500866Z",
     "end_time": "2023-05-08T17:15:20.222159Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#nainÅ¡talujte\n",
    "#!pip install isbnlib"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.224395Z",
     "end_time": "2023-05-08T17:15:20.225467Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# df = pd.read_csv('data/rec-amz-Books.edges', header=None, names=['ID_reviewer', 'ISBN', 'Stars', 'Date'])\n",
    "# display(df['ISBN'].value_counts())\n",
    "# display(df['ID_reviewer'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.228511Z",
     "end_time": "2023-05-08T17:15:20.235248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# np.ones((87085, 87085))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.236754Z",
     "end_time": "2023-05-08T17:15:20.242426Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# np.ones((10356390, 10356390))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.244426Z",
     "end_time": "2023-05-08T17:15:20.259372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def subgraphByListOfValues(values: pd.Series, column: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df[np.isin(df[column], values)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.256865Z",
     "end_time": "2023-05-08T17:15:20.260372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def randomSubgraph(n:int, column: str, df: pd.DataFrame, weighed: bool = True, seed: int = 3, minDeg: int= 10) -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    values, counts = np.unique(df[column], return_counts=True)\n",
    "    values, counts = values[counts > minDeg],  counts[counts > minDeg] # nech nemame knihy s velmi malo hodnoteniami (resp uzivatelov co majo citaju)\n",
    "    return subgraphByListOfValues(np.random.choice(values, n, replace=False, p=(counts / sum(counts)) if weighed else None), column, df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.259372Z",
     "end_time": "2023-05-08T17:15:20.270376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class RecommendationEngine:\n",
    "    def __init__(self, filename: str, seed: int=3, n: int = 200, col: str = \"ISBN\"):\n",
    "        self.df = pd.read_csv(filename, header=None, names=['ID_reviewer', 'ISBN','Stars','Date'])\n",
    "        self.subdf = randomSubgraph(n, col, self.df, seed=seed)\n",
    "        self.SM = {True: None, False: None}\n",
    "        self.SMC = {True: None, False: None}\n",
    "        self.G: nx.classes.graph.Graph = nx.from_pandas_edgelist(self.subdf, source='ID_reviewer', target='ISBN', edge_attr='Stars')\n",
    "        self.userOrder = self.filterNodes(True)\n",
    "        self.bookOrder = self.filterNodes(False)\n",
    "\n",
    "    def filterNodes(self, users: bool) -> list[str]:\n",
    "        return list(filter(lambda x: (x[0] == 'A') if users else (x[0] != 'A'), self.G.nodes()))\n",
    "\n",
    "    def similarityMatrix(self, users: bool, save: bool=False) -> pd.DataFrame:  # use wisely!\n",
    "        if self.SM[users] is not None:\n",
    "            return self.SM[users]\n",
    "        userOrder = self.filterNodes(True)\n",
    "        bookOrder = self.filterNodes(False)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder, bookOrder).toarray()\n",
    "        product = A @ A.T if users else A.T @ A\n",
    "        np.fill_diagonal(product, 0)\n",
    "        order = userOrder if users else bookOrder\n",
    "        SM = pd.DataFrame(product, columns = order)\n",
    "        SM.index = order\n",
    "        if save:\n",
    "            self.SM[users] = SM\n",
    "        return SM\n",
    "\n",
    "    def similarityMatrixCosine(self, users: bool, save: bool=False) -> np.ndarray:  # use wisely!\n",
    "        if self.SMC[users] is not None:\n",
    "            return self.SMC[users]\n",
    "        SM = self.similarityMatrix(users)\n",
    "        norms = (np.linalg.norm(SM, axis=1))\n",
    "        SMC = SM / norms[:, None] / norms[None, :]\n",
    "        np.nan_to_num(SMC, copy=False)\n",
    "        if save:\n",
    "            self.SMC[users] = SMC\n",
    "        return SMC\n",
    "\n",
    "    def similarityVectorForUser(self, user:str, userOrder:list[str] = None, cosine:bool = True):\n",
    "        if userOrder is None:\n",
    "            userOrder = self.filterNodes(True)\n",
    "        u = userOrder.index(user)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder, weight='Stars').toarray()\n",
    "        result = np.zeros((len(userOrder)))\n",
    "        for r in range(len(userOrder)):\n",
    "            result[r] = np.dot(A[r, :], A[u, :])\n",
    "            if cosine:\n",
    "                result[r] /= np.sqrt(np.dot(A[r, :], A[r, :]))\n",
    "        if cosine:\n",
    "            result /= np.sqrt(np.dot(A[u, :], A[u, :]))\n",
    "        result[u] = 0\n",
    "        return result, np.array(userOrder)\n",
    "\n",
    "    def getNMostSimilarUsers(self, user:str, n:int, ignoreTotalMatch=True):\n",
    "        sim, users = self.similarityVectorForUser(user, cosine=True)\n",
    "        if ignoreTotalMatch:\n",
    "            sim, users = sim[sim < 0.9999], users[sim < 0.9999]\n",
    "        sim.argsort()\n",
    "        return users[sim.argsort()[-n:]]\n",
    "\n",
    "    def getSimilarBooksToABook(self, book):\n",
    "        df = self.similarityMatrixCosine(False)\n",
    "        return list(df[book][df[book] == df[book].max()].index)\n",
    "\n",
    "    def getMetaFromISBN(self,isbn:str) -> json:\n",
    "      SERVICE = \"goob\"\n",
    "      format_json = bibformatters[\"json\"]\n",
    "      meta_data = (format_json(meta(isbn, SERVICE)))\n",
    "      #print(meta_data)\n",
    "      return meta_data\n",
    "\n",
    "    def fromJsonToDict(self,json_file:json) -> dict:\n",
    "      return json.loads(json_file)\n",
    "\n",
    "    def getDf(self)->pd.DataFrame:\n",
    "      return self.subdf\n",
    "\n",
    "    def getBooksByUser(self,df:pd.DataFrame,id:str) ->list: #(list of ISBN for user)\n",
    "      df = df.loc[df['ID_reviewer']==id, 'ISBN'].values\n",
    "      return df\n",
    "\n",
    "    def getBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list: #same - same books, diff - different books\n",
    "      b1 = self.getBooksByUser(self.getDf(),id1)\n",
    "      b2 = self.getBooksByUser(self.getDf(),id2)\n",
    "      if type_ == \"same\":\n",
    "        return list(set(b1).intersection(set(b2)))\n",
    "      elif type_ == \"diff1\":\n",
    "        return list(set(b2) - set(b1)) #vsetky knihy od id2, ktore id1 necital\n",
    "      elif type_ == \"diff2\":\n",
    "        return list(set(b1) - set(b2)) #vsetky knihy od id1, ktore id2 necital\n",
    "\n",
    "    def getSimilarBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list:  #type ==(year, publisher)\n",
    "        if type_ == \"year\": #odporucame id1 knihy od uzivatela id2 na zaklade roku vydania knihy\n",
    "          books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "          #print(books_s)\n",
    "          years = list()\n",
    "          for i in range(len(books_s)): #zoberieme vseetky roky a pozrieme sa aky najviac prevlada -> zoberiem okolie (-5,5) a to odporucime\n",
    "            pom = self.getMetaFromISBN(books_s[i])\n",
    "            if pom != None: #nenaslo ISBN\n",
    "              years.append(self.fromJsonToDict(pom)[\"year\"])\n",
    "          most_common_era = Counter(years).most_common(1) #rok,pocet_opakovani\n",
    "          most_common_era = [int(most_common_era[0][0])-5,int(most_common_era[0][0])+5]\n",
    "          #print(most_common_era)\n",
    "          books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "          recommendation_by_year = list()\n",
    "          for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su medzi most_common_era\n",
    "            pom = self.getMetaFromISBN(books_d[i])\n",
    "            if pom != None: #nenaslo ISBN\n",
    "              if most_common_era[0] <= (int(self.fromJsonToDict(pom)[\"year\"])) <= most_common_era[1]:\n",
    "                title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                authors = list()\n",
    "                for i in range(len(self.fromJsonToDict(pom)[\"author\"])):  #ak mame viac autorov\n",
    "                  authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                recommendation_by_year.append([title,year, authors])\n",
    "                #print(recommendation_by_year)\n",
    "          if recommendation_by_year == []:\n",
    "            recommendation_by_year = [(\"Nenasli sa ziadne knihy z rokov:\",most_common_era[0],\"-\",most_common_era[1])]\n",
    "          return recommendation_by_year\n",
    "\n",
    "        elif type_ == \"publisher\": #odporucame id1 knihy od uzivatela id2, vyberame oblubeneho vydavatelstvo\n",
    "           books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "           publishers = list()\n",
    "           for i in range(len(books_s)): #zoberieme vseetky vydavatelstva -> most_common\n",
    "              pom = self.getMetaFromISBN(books_s[i])\n",
    "              if pom != None: #nenaslo ISBN\n",
    "                publishers.append(self.fromJsonToDict(pom)[\"publisher\"])\n",
    "           most_common_publisher = Counter(publishers).most_common(1) #vydavatelstvo,pocet_opakovani\n",
    "           print(most_common_publisher)\n",
    "           books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "           recommendation_by_publisher = list()\n",
    "           for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su od most_common_publishe\n",
    "              pom = self.getMetaFromISBN(books_d[i])\n",
    "              if pom != None: #nenaslo ISBN\n",
    "                if most_common_publisher[0] == (self.fromJsonToDict(pom)[\"publisher\"]):\n",
    "                  title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                  year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                  authors = list()\n",
    "                  for i in range(len(self.fromJsonToDict(pom)[\"author\"])): #ak mame viac autorov\n",
    "                    authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                  recommendation_by_publisher.append([title,year, authors])\n",
    "                #print(recommendation_by_year)\n",
    "           if recommendation_by_publisher == []:\n",
    "              recommendation_by_publisher = [\"Nenasli sa ziadne knihy od oblubeneho vydavatela\"]\n",
    "           return recommendation_by_publisher\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.266375Z",
     "end_time": "2023-05-08T17:15:20.290000Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:15:20.290000Z",
     "end_time": "2023-05-08T17:16:53.493489Z"
    }
   },
   "outputs": [],
   "source": [
    "re = RecommendationEngine('data/rec-amz-Books.edges', n=200, seed=76972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 87085\n"
     ]
    }
   ],
   "source": [
    "print(f'number of users: {len(re.filterNodes(True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:16:53.495647Z",
     "end_time": "2023-05-08T17:16:53.536246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 most similar users to A2BWZNAJCDKQ96: ['A1FTBXHM3DJTEA' 'ARSDJ482Z8MGV' 'AI3AUM07TTPE1']\n",
      "most similar books to 1477448616: ['B00DP8R3P4']\n"
     ]
    }
   ],
   "source": [
    "randomUser = np.random.choice(re.filterNodes(True))\n",
    "randomBook = np.random.choice(re.filterNodes(False))\n",
    "print(f'3 most similar users to {randomUser}: {re.getNMostSimilarUsers(randomUser, 3)}')\n",
    "print(f'most similar books to {randomBook}: {re.getSimilarBooksToABook(randomBook)}')# vela podobnych znamena, ze kniha si nie je podobna so ziadnou knihou, teda je izolovana"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:16:53.522450Z",
     "end_time": "2023-05-08T17:17:42.802121Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ukazkovy outupt:\n",
    "most similar books to 1858600073: ['0786407735']\n",
    "ku knihe \"They Walked With Jesus: Past Life Experience With Christ\", to naslo \"Genocide and Rescue in Wolyn: Recollections of the Ukrainian Nationalist Ethnic Cleansing Campaign Against the Poles During World War II\", co myslim nie je uplne odveci odporucanie (na to aku malu podmnozinu knih mame)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pri hladani podobnych uzivatelov ignoreTotalMatch paraemter True ignoruje dokonale podobnych pouzivatelov, ty bu nemali ake ine knihy odporucit\n",
    "pri podobnych knihach, uz chceme ja dokolane zhody"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "            006057531X  0060593237  0060937750  0060987103  0061120618   \n006057531X           0           0           0           0           0  \\\n0060593237           0           0           0           0           0   \n0060937750           0           0           0           1           0   \n0060987103           0           0           1           0           0   \n0061120618           0           0           0           0           0   \n...                ...         ...         ...         ...         ...   \nB00HCTPAXE           0           0           0           0           0   \nB00HG3COP8           0           0           0           0           0   \nB00KSBQI84           0           0           0           0           0   \nB00L6HH1O4           0           0           0           0           0   \nB00L7H0RXA           0           0           0           0           0   \n\n            0061537934  0061774804  0061950726  0062022326  0071445137  ...   \n006057531X           1           0           0           1           0  ...  \\\n0060593237           0           0           0           0           0  ...   \n0060937750           0           0           0           0           0  ...   \n0060987103          23           2           2           0           0  ...   \n0061120618           2           0           0           0           0  ...   \n...                ...         ...         ...         ...         ...  ...   \nB00HCTPAXE           0           0           0           0           0  ...   \nB00HG3COP8           0           0           0           0           0  ...   \nB00KSBQI84           0           0           0           0           0  ...   \nB00L6HH1O4           0           0           0           0           0  ...   \nB00L7H0RXA           0           0           0           0           0  ...   \n\n            B00C2L7N4G  B00CK8CKZS  B00DP8R3P4  B00GJ371PE  B00H39Y6ZQ   \n006057531X           0           0           0           0           0  \\\n0060593237           0           0           0           0           0   \n0060937750           0           0           0           0           0   \n0060987103           0           0           0           0           0   \n0061120618           0           0           0           0           0   \n...                ...         ...         ...         ...         ...   \nB00HCTPAXE           0           0           0           0           0   \nB00HG3COP8           0           0           0           0           0   \nB00KSBQI84           0           0           0           0           0   \nB00L6HH1O4           0           0           0           0           0   \nB00L7H0RXA           0           0           0           0           0   \n\n            B00HCTPAXE  B00HG3COP8  B00KSBQI84  B00L6HH1O4  B00L7H0RXA  \n006057531X           0           0           0           0           0  \n0060593237           0           0           0           0           0  \n0060937750           0           0           0           0           0  \n0060987103           0           0           0           0           0  \n0061120618           0           0           0           0           0  \n...                ...         ...         ...         ...         ...  \nB00HCTPAXE           0           0           0           0           0  \nB00HG3COP8           0           0           0           0           0  \nB00KSBQI84           0           0           0           0           0  \nB00L6HH1O4           0           0           0           0           0  \nB00L7H0RXA           0           0           0           0           0  \n\n[200 rows x 200 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>006057531X</th>\n      <th>0060593237</th>\n      <th>0060937750</th>\n      <th>0060987103</th>\n      <th>0061120618</th>\n      <th>0061537934</th>\n      <th>0061774804</th>\n      <th>0061950726</th>\n      <th>0062022326</th>\n      <th>0071445137</th>\n      <th>...</th>\n      <th>B00C2L7N4G</th>\n      <th>B00CK8CKZS</th>\n      <th>B00DP8R3P4</th>\n      <th>B00GJ371PE</th>\n      <th>B00H39Y6ZQ</th>\n      <th>B00HCTPAXE</th>\n      <th>B00HG3COP8</th>\n      <th>B00KSBQI84</th>\n      <th>B00L6HH1O4</th>\n      <th>B00L7H0RXA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>006057531X</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0060593237</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0060937750</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0060987103</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0061120618</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>B00HCTPAXE</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00HG3COP8</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00KSBQI84</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00L6HH1O4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B00L7H0RXA</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows Ã 200 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(re.similarityMatrix(False, save=True))\n",
    "# pre users je matica moc velka...n neodporucam to skusat, a ani pre vela knih, to dlho trava..., lebo je tem vela user-ov, ale za cca min to zvladne"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:17:42.804122Z",
     "end_time": "2023-05-08T17:18:37.143416Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pre cast niszie, novy seed asi dost upravil podmnozinu pouzivatelov a knih, ktora bola vybrana"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'book', 'title': 'Heavenly Highway Hymns: Shaped-Note Hymnal', 'author': [{'name': 'Stamps/Baxter'}], 'year': '1983', 'identifier': [{'type': 'ISBN', 'id': '9780000013712'}], 'publisher': 'Brentwood Benson'}\n",
      "Brentwood Benson\n"
     ]
    }
   ],
   "source": [
    "meta_json_book = re.getMetaFromISBN(\"0000013714\")\n",
    "list_meta = re.fromJsonToDict(meta_json_book)\n",
    "print(list_meta)\n",
    "print(list_meta[\"publisher\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:18:37.145479Z",
     "end_time": "2023-05-08T17:18:37.703752Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "same: []\n",
      "diff1: []\n",
      "diff2: []\n"
     ]
    }
   ],
   "source": [
    "print(re.getBooksByUser(re.getDf(),\"A1KP12IVP6LAGL\"))\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"same\")\n",
    "print(\"same:\" ,books_users)\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"diff1\")\n",
    "print(\"diff1:\" ,books_users)\n",
    "books_users = re.getBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"diff2\")\n",
    "print(\"diff2:\" ,books_users)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T17:18:37.691616Z",
     "end_time": "2023-05-08T17:18:37.795698Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation by year: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecommendation by year: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m books_recomendation \u001B[38;5;241m=\u001B[39m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetSimilarBooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetDf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mA1KP12IVP6LAGL\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mAG7R3MMF8QLDT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(books_recomendation)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRecommendation by publisher: \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[8], line 103\u001B[0m, in \u001B[0;36mRecommendationEngine.getSimilarBooks\u001B[1;34m(self, df, id1, id2, type_)\u001B[0m\n\u001B[0;32m    101\u001B[0m     years\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfromJsonToDict(pom)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m    102\u001B[0m most_common_era \u001B[38;5;241m=\u001B[39m Counter(years)\u001B[38;5;241m.\u001B[39mmost_common(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;66;03m#rok,pocet_opakovani\u001B[39;00m\n\u001B[1;32m--> 103\u001B[0m most_common_era \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(\u001B[43mmost_common_era\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5\u001B[39m,\u001B[38;5;28mint\u001B[39m(most_common_era[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m5\u001B[39m]\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m#print(most_common_era)\u001B[39;00m\n\u001B[0;32m    105\u001B[0m books_d \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgetBooks(df,id1,id2,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiff1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Recommendation by year: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"year\")\n",
    "print(books_recomendation)\n",
    "print(\"Recommendation by publisher: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A1KP12IVP6LAGL\",\"AG7R3MMF8QLDT\",\"publisher\")\n",
    "print(books_recomendation)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
