{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "from collections import Counter\n",
    "#nainštalujte pip install isbnlib\n",
    "from isbnlib import meta\n",
    "from isbnlib.registry import bibformatters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.769012Z",
     "end_time": "2023-05-08T19:22:01.848434Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pamäť pre celú sieť maticu susedností nedostaneme...:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 780. TiB for an array with shape (10356390, 10356390) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[174], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10356390\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10356390\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\numeric.py:205\u001B[0m, in \u001B[0;36mones\u001B[1;34m(shape, dtype, order, like)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ones_with_like(shape, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, like\u001B[38;5;241m=\u001B[39mlike)\n\u001B[1;32m--> 205\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    206\u001B[0m multiarray\u001B[38;5;241m.\u001B[39mcopyto(a, \u001B[38;5;241m1\u001B[39m, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 780. TiB for an array with shape (10356390, 10356390) and data type float64"
     ]
    }
   ],
   "source": [
    "# np.ones((10356390, 10356390))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.789975Z",
     "end_time": "2023-05-08T19:22:02.006306Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dokonca ani pre malú časť vrcholov"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 56.5 GiB for an array with shape (87085, 87085) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[173], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m87085\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m87085\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\numeric.py:205\u001B[0m, in \u001B[0;36mones\u001B[1;34m(shape, dtype, order, like)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ones_with_like(shape, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, like\u001B[38;5;241m=\u001B[39mlike)\n\u001B[1;32m--> 205\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[43mempty\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    206\u001B[0m multiarray\u001B[38;5;241m.\u001B[39mcopyto(a, \u001B[38;5;241m1\u001B[39m, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m a\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 56.5 GiB for an array with shape (87085, 87085) and data type float64"
     ]
    }
   ],
   "source": [
    "# np.ones((87085, 87085))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vytvoríme si podgraf, vyberieme si náhodnú podmnožinu kníh (alebo čitateľov) a k nim všetky hrany (z druhej skupiny vrcholov zoberieme všetky potrebné vrcholy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "def subgraphByListOfValues(values: pd.Series, column: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    #\n",
    "    return df[np.isin(df[column], values)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.802571Z",
     "end_time": "2023-05-08T19:22:02.007306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [
    "def randomSubgraph(n:int, column: str, df: pd.DataFrame, weighed: bool = True, seed: int = 3, minDeg: int= 10) -> pd.DataFrame:\n",
    "    np.random.seed(seed)\n",
    "    values, counts = np.unique(df[column], return_counts=True)\n",
    "    values, counts = values[counts > minDeg],  counts[counts > minDeg] # nech nemame knihy s velmi malo hodnoteniami (resp uzivatelov co majo citaju)\n",
    "    return subgraphByListOfValues(np.random.choice(values, n, replace=False, p=(counts / sum(counts)) if weighed else None), column, df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.811590Z",
     "end_time": "2023-05-08T19:22:02.021852Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "class RecommendationEngine:\n",
    "    def __init__(self, filename: str, seed: int=3, n: int = 200, col: str = \"ISBN\"):\n",
    "        self.df = pd.read_csv(filename, header=None, names=['ID_reviewer', 'ISBN','Stars','Date'])\n",
    "        self.subdf = randomSubgraph(n, col, self.df, seed=seed)\n",
    "        self.SM = {True: None, False: None}\n",
    "        self.SMC = {True: None, False: None}\n",
    "        self.G: nx.classes.graph.Graph = nx.from_pandas_edgelist(self.subdf, source='ID_reviewer', target='ISBN', edge_attr='Stars')\n",
    "        self.userOrder = self.filterNodes(True)\n",
    "        self.bookOrder = self.filterNodes(False)\n",
    "\n",
    "    def filterNodes(self, users: bool) -> list[str]:\n",
    "        # vypis zoznamu knih/citatelov\n",
    "        return list(filter(lambda x: (x[0] == 'A') if users else (x[0] != 'A'), self.G.nodes()))\n",
    "\n",
    "    def similarityMatrix(self, users: bool, save: bool=False) -> pd.DataFrame:  # use wisely!\n",
    "        # vypocet matice podobnosti (poctu zhodnych susedov)\n",
    "        if self.SM[users] is not None:\n",
    "            return self.SM[users]\n",
    "        userOrder = self.filterNodes(True)\n",
    "        bookOrder = self.filterNodes(False)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder, bookOrder).toarray()\n",
    "        product = A @ A.T if users else A.T @ A\n",
    "        np.fill_diagonal(product, 0) # citatel si so sebou nie je podobny (nech nam ho neodporuca)\n",
    "        order = userOrder if users else bookOrder # priradenie id k hodnotam\n",
    "        SM = pd.DataFrame(product, columns = order)\n",
    "        SM.index = order\n",
    "        if save:\n",
    "            self.SM[users] = SM\n",
    "        return SM\n",
    "\n",
    "    def similarityMatrixCosine(self, users: bool, save: bool=False) -> np.ndarray:  # use wisely!\n",
    "        # vypocet matice kosinusovej podobnosti\n",
    "        if self.SMC[users] is not None:\n",
    "            return self.SMC[users]\n",
    "        SM = self.similarityMatrix(users)\n",
    "        norms = (np.linalg.norm(SM, axis=1))\n",
    "        SMC = SM / norms[:, None] / norms[None, :]\n",
    "        np.nan_to_num(SMC, copy=False)\n",
    "        if save:\n",
    "            self.SMC[users] = SMC\n",
    "        return SMC\n",
    "\n",
    "    def similarityVectorForUser(self, user:str, userOrder:list[str] = None, cosine:bool = True):\n",
    "        #vypocet vektora podobnosti usera so vsetkymi ostatnymi citatelmi\n",
    "        if userOrder is None:\n",
    "            userOrder = self.filterNodes(True)\n",
    "        u = userOrder.index(user)\n",
    "        A = nx.algorithms.bipartite.matrix.biadjacency_matrix(self.G, userOrder, weight='Stars').toarray()\n",
    "        result = np.zeros((len(userOrder)))\n",
    "        for r in range(len(userOrder)):\n",
    "            result[r] = np.dot(A[r, :], A[u, :])\n",
    "            if cosine:\n",
    "                result[r] /= np.sqrt(np.dot(A[r, :], A[r, :]))\n",
    "        if cosine:\n",
    "            result /= np.sqrt(np.dot(A[u, :], A[u, :]))\n",
    "        result[u] = 0\n",
    "        return result, np.array(userOrder)\n",
    "\n",
    "    def getNMostSimilarUsers(self, user:str, n:int, ignoreTotalMatch=True):\n",
    "        # najdeme vektor podobnosti usera s vsetkymi ostatnymi\n",
    "        sim, users = self.similarityVectorForUser(user, cosine=True)\n",
    "        if ignoreTotalMatch:\n",
    "            sim, users = sim[sim < 0.9999], users[sim < 0.9999] #odfiltrujeme dokonale zhody\n",
    "        sim.argsort()\n",
    "        return users[sim.argsort()[-n:]] # najdeme n najpodobnejsich\n",
    "\n",
    "    def getSimilarBooksToABook(self, book):\n",
    "        # vypocitame maticu podobnosti knih, najdeme a najpodobnejsiu knihu, zadanej knihe\n",
    "        df = self.similarityMatrixCosine(False)\n",
    "        return list(df[book][df[book] == df[book].max()].index)\n",
    "\n",
    "    def getMetaFromISBN(self,isbn:str) -> json:\n",
    "        try:\n",
    "            SERVICE = \"goob\"\n",
    "            format_json = bibformatters[\"json\"]\n",
    "            meta_data = (format_json(meta(isbn, SERVICE)))\n",
    "            #print(meta_data)\n",
    "            return meta_data\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def fromJsonToDict(self,json_file:json) -> dict:\n",
    "        if json_file is None:\n",
    "            return dict()\n",
    "        return json.loads(json_file)\n",
    "\n",
    "    def getDf(self)->pd.DataFrame:\n",
    "      return self.subdf\n",
    "\n",
    "    def getBooksByUser(self, id:str) ->list: #(list of ISBN for user)\n",
    "      # df = df.loc[df['ID_reviewer']==id, 'ISBN'].values\n",
    "      # return df\n",
    "        return list(self.G.neighbors(id))\n",
    "\n",
    "    def getBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list: #same - same books, diff - different books\n",
    "      b1 = self.getBooksByUser(id1)\n",
    "      b2 = self.getBooksByUser(id2)\n",
    "      if type_ == \"same\":\n",
    "        return list(set(b1).intersection(set(b2)))\n",
    "      elif type_ == \"diff1\":\n",
    "        return list(set(b2) - set(b1)) #vsetky knihy od id2, ktore id1 necital\n",
    "      elif type_ == \"diff2\":\n",
    "        return list(set(b1) - set(b2)) #vsetky knihy od id1, ktore id2 necital\n",
    "\n",
    "    def getSimilarBooks(self,df:pd.DataFrame,id1:str,id2:str,type_:str) ->list:  #type ==(year, publisher)\n",
    "        try:\n",
    "            if type_ == \"year\": #odporucame id1 knihy od uzivatela id2 na zaklade roku vydania knihy\n",
    "              books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "              #print(books_s)\n",
    "              years = list()\n",
    "              for i in range(len(books_s)): #zoberieme vseetky roky a pozrieme sa aky najviac prevlada -> zoberiem okolie (-5,5) a to odporucime\n",
    "                pom = self.getMetaFromISBN(books_s[i])\n",
    "                if pom != None: #nenaslo ISBN\n",
    "                  years.append(self.fromJsonToDict(pom)[\"year\"])\n",
    "              most_common_era = Counter(years).most_common(1) #rok,pocet_opakovani\n",
    "              most_common_era = [int(most_common_era[0][0])-5,int(most_common_era[0][0])+5]\n",
    "              #print(most_common_era)\n",
    "              books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "              recommendation_by_year = list()\n",
    "              for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su medzi most_common_era\n",
    "                pom = self.getMetaFromISBN(books_d[i])\n",
    "                if pom != None: #nenaslo ISBN\n",
    "                  if most_common_era[0] <= (int(self.fromJsonToDict(pom)[\"year\"])) <= most_common_era[1]:\n",
    "                    title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                    year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                    authors = list()\n",
    "                    for i in range(len(self.fromJsonToDict(pom)[\"author\"])):  #ak mame viac autorov\n",
    "                      authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                    recommendation_by_year.append([title,year, authors])\n",
    "                    #print(recommendation_by_year)\n",
    "              if recommendation_by_year == []:\n",
    "                recommendation_by_year = [(\"Nenasli sa ziadne knihy z rokov:\",most_common_era[0],\"-\",most_common_era[1])]\n",
    "              return recommendation_by_year\n",
    "\n",
    "            elif type_ == \"publisher\": #odporucame id1 knihy od uzivatela id2, vyberame oblubeneho vydavatelstvo\n",
    "               books_s = self.getBooks(df,id1,id2,\"same\")\n",
    "               publishers = list()\n",
    "               for i in range(len(books_s)): #zoberieme vseetky vydavatelstva -> most_common\n",
    "                  pom = self.getMetaFromISBN(books_s[i])\n",
    "                  if pom != None: #nenaslo ISBN\n",
    "                    publishers.append(self.fromJsonToDict(pom)[\"publisher\"])\n",
    "               most_common_publisher = Counter(publishers).most_common(1) #vydavatelstvo,pocet_opakovani\n",
    "               # print(most_common_publisher)\n",
    "               books_d = self.getBooks(df,id1,id2,\"diff1\")\n",
    "               recommendation_by_publisher = list()\n",
    "               for i in range(len(books_d)): #zistime info o vsetkych kniha id2 a vyberieme nazvy tych ktorych vydania su od most_common_publishe\n",
    "                  pom = self.getMetaFromISBN(books_d[i])\n",
    "                  if pom != None: #nenaslo ISBN\n",
    "                    if most_common_publisher[0] == (self.fromJsonToDict(pom)[\"publisher\"]):\n",
    "                      title = self.fromJsonToDict(pom)[\"title\"]\n",
    "                      year = self.fromJsonToDict(pom)[\"year\"]\n",
    "                      authors = list()\n",
    "                      for i in range(len(self.fromJsonToDict(pom)[\"author\"])): #ak mame viac autorov\n",
    "                        authors.append(self.fromJsonToDict(pom)[\"author\"][i]['name'])\n",
    "                      recommendation_by_publisher.append([title,year, authors])\n",
    "                    #print(recommendation_by_year)\n",
    "               if recommendation_by_publisher == []:\n",
    "                  recommendation_by_publisher = [\"Nenasli sa ziadne knihy od oblubeneho vydavatela\"]\n",
    "               return recommendation_by_publisher\n",
    "        except:\n",
    "            return [\"Nenasli sa ziadne knihy\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.823517Z",
     "end_time": "2023-05-08T19:22:02.042164Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:22:01.986850Z",
     "end_time": "2023-05-08T19:24:28.662426Z"
    }
   },
   "outputs": [],
   "source": [
    "re = RecommendationEngine('data/rec-amz-Books.edges', n=200, seed=76972)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Počet čitateľov: 87085\n"
     ]
    }
   ],
   "source": [
    "print(f'Počet čitateľov: {len(re.filterNodes(True))}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:24:28.664425Z",
     "end_time": "2023-05-08T19:24:28.739380Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O knihách vieme dohľadať info z datábazy:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN:  0061537934\n",
      "Názov knihy:  The Art Of Racing In The Rain\n",
      "Autor:  Garth Stein\n",
      "Rok vydania:  2008\n",
      "Vydavateľstvo:  Harper\n"
     ]
    }
   ],
   "source": [
    "meta_json_book = re.getMetaFromISBN(\"0061537934\")\n",
    "list_meta = re.fromJsonToDict(meta_json_book)\n",
    "# print(list_meta)\n",
    "print(\"ISBN: \", \"0061537934\")\n",
    "print(\"Názov knihy: \",list_meta[\"title\"])\n",
    "print(\"Autor: \",list_meta[\"author\"][0]['name'])\n",
    "print(\"Rok vydania: \",list_meta[\"year\"])\n",
    "print(\"Vydavateľstvo: \",list_meta[\"publisher\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:24:28.741380Z",
     "end_time": "2023-05-08T19:24:28.753150Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ku knihám vieme odporučiť podobné"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar books to \"Zoo\"(0316097446): \"The Tesla Gate\"(1624671772)\n",
      "similar books: 1\n"
     ]
    }
   ],
   "source": [
    "randomBook = np.random.choice(re.filterNodes(False))\n",
    "simBs = re.getSimilarBooksToABook(randomBook)\n",
    "simB = simBs[0]\n",
    "print(f'most similar books to \\\"{re.fromJsonToDict(re.getMetaFromISBN(randomBook))[\"title\"]}\\\"({randomBook}): \\\"{re.fromJsonToDict(re.getMetaFromISBN(simB))[\"title\"]}\\\"({simB})')\n",
    "print(f\"similar books: {len(simBs)}\") # vela podobnych znamena, ze kniha si nie je podobna so ziadnou knihou, teda je izolovana"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:36:48.677786Z",
     "end_time": "2023-05-08T19:37:41.915999Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "K používateľom vieme nájsť ďalších s podobným vkusom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 most similar users to A2BWZNAJCDKQ96: ['A1FTBXHM3DJTEA' 'ARSDJ482Z8MGV' 'AI3AUM07TTPE1']\n"
     ]
    }
   ],
   "source": [
    "randomUser = np.random.choice(re.filterNodes(True))\n",
    "print(f'3 most similar users to {randomUser}: {re.getNMostSimilarUsers(randomUser, 3)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:25:40.921803Z",
     "end_time": "2023-05-08T19:25:43.458803Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A odporučiť ďalšie čítanie od čitateľov s podobným vkusom"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Čitateľ AHUT55E980RDR čítal \n",
      "Shoot Don't Shoot\n",
      "Blood Work\n",
      "Lola's Secret - A Novel\n",
      "S.E.C.R.E.T: S.E.C.R.E.T.--S.E.C.R.E.T.--1\n",
      "Caring For A Loved One With Cancer\n",
      "The Flamethrowers - A Novel\n",
      "Exodus\n",
      " Odporúčame mu knihy \n",
      "The Atlantis Gene\n"
     ]
    }
   ],
   "source": [
    "user = np.random.choice(list(map(lambda x: x[0], filter(lambda x: x[1] > 5, list(re.G.degree(re.filterNodes(True)))))))\n",
    "# a, b, c = re.getNMostSimilarUsers(user, 3)\n",
    "recommendation = []\n",
    "for u in re.getNMostSimilarUsers(user, 3):\n",
    "    try:\n",
    "        recommendation += re.getBooks(re.getDf(),user,u,\"diff1\")\n",
    "    except:\n",
    "        pass\n",
    "recoStr = '\\n'.join(map(lambda x: x['title'], filter(lambda x: \"title\" in x, map(lambda x: re.fromJsonToDict(re.getMetaFromISBN(x)), recommendation))))\n",
    "already = re.getBooksByUser(user)\n",
    "alrStr = '\\n'.join(map(lambda x: x['title'], filter(lambda x: \"title\" in x, map(lambda x: re.fromJsonToDict(re.getMetaFromISBN(x)), already))))\n",
    "print(f\"Čitateľ {user} čítal \\n{alrStr}\\n Odporúčame mu knihy \\n{recoStr}\")\n",
    "    # print(u)\n",
    "    # books_users = re.getBooks(re.getDf(),user,u,\"same\")\n",
    "    # print(\"same:\" ,books_users)\n",
    "    # books_users = re.getBooks(re.getDf(),user,u,\"diff1\")\n",
    "    # print(\"diff1:\" ,books_users)\n",
    "    # books_users = re.getBooks(re.getDf(),user,u,\"diff2\")\n",
    "    # print(\"diff2:\" ,books_users)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:35:05.293415Z",
     "end_time": "2023-05-08T19:35:15.317473Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pre malú podsieť funkcie pre výber podľa vydavateľa alebo roku nefungujú dobre, potrebovali by sme väčšiu množinu kníh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation by year: \n",
      "['Nenasli sa ziadne knihy']\n",
      "Recommendation by publisher: \n",
      "[]\n",
      "['Nenasli sa ziadne knihy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Recommendation by year: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A2BWZNAJCDKQ96\",\"A1FTBXHM3DJTEA\",\"year\")\n",
    "print(books_recomendation)\n",
    "print(\"Recommendation by publisher: \")\n",
    "books_recomendation = re.getSimilarBooks(re.getDf(),\"A2BWZNAJCDKQ96\",\"A1FTBXHM3DJTEA\",\"publisher\")\n",
    "print(books_recomendation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T19:44:20.731391Z",
     "end_time": "2023-05-08T19:44:20.737558Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
